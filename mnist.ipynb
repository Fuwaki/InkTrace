{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b728d92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "print(\"库导入成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48a4c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepVit 模型导入成功！\n",
      "使用 repvit_m0_6（最小版本，CPU 运行最快）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/.venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/RepVit.py:277: UserWarning: Overwriting repvit_m0_9 in registry with RepVit.repvit_m0_9. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def repvit_m0_9(pretrained=False, num_classes = 1000, distillation=False):\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/RepVit.py:313: UserWarning: Overwriting repvit_m1_0 in registry with RepVit.repvit_m1_0. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def repvit_m1_0(pretrained=False, num_classes = 1000, distillation=False):\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/RepVit.py:350: UserWarning: Overwriting repvit_m1_1 in registry with RepVit.repvit_m1_1. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def repvit_m1_1(pretrained=False, num_classes = 1000, distillation=False):\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/RepVit.py:385: UserWarning: Overwriting repvit_m1_5 in registry with RepVit.repvit_m1_5. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def repvit_m1_5(pretrained=False, num_classes = 1000, distillation=False):\n",
      "/run/media/fuwaki/Workspace/Workspace/Python/InkTrace/RepVit.py:439: UserWarning: Overwriting repvit_m2_3 in registry with RepVit.repvit_m2_3. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def repvit_m2_3(pretrained=False, num_classes = 1000, distillation=False):\n"
     ]
    }
   ],
   "source": [
    "from RepVit import repvit_m0_6\n",
    "\n",
    "print(\"RepVit 模型导入成功！\")\n",
    "print(\"使用 repvit_m0_6（最小版本，CPU 运行最快）\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c78716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform 定义完成\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理：定义 transform\n",
    "# 关键点：\n",
    "# - Resize(64): 防止 RepViT 下采样导致特征图消失\n",
    "# - Grayscale(3): 把单通道变成 3 通道，适配 RepViT 的输入层\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "print(\"Transform 定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cabebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在下载/加载 MNIST 数据...\n",
      "训练集大小: 60000\n",
      "测试集大小: 10000\n"
     ]
    }
   ],
   "source": [
    "# 下载/加载 MNIST 数据集\n",
    "print(\"正在下载/加载 MNIST 数据...\")\n",
    "train_dataset = datasets.MNIST(\n",
    "    \"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False, transform=transform)\n",
    "print(f\"训练集大小: {len(train_dataset)}\")\n",
    "print(f\"测试集大小: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3e7f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练 DataLoader: 1875 batches\n",
      "测试 DataLoader: 313 batches\n"
     ]
    }
   ],
   "source": [
    "# 创建 DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"训练 DataLoader: {len(train_loader)} batches\")\n",
    "print(f\"测试 DataLoader: {len(test_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892a34ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型初始化完成\n",
      "模型参数数量: 2,169,502\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型、优化器和损失函数\n",
    "model = repvit_m0_6(num_classes=10)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"模型初始化完成\")\n",
    "print(f\"模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e1db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 开始训练 (共 1 轮) ===\n",
      "Epoch: 1 | Batch: 0/1875 | Loss: 2.4205\n",
      "Epoch: 1 | Batch: 10/1875 | Loss: 1.1626\n",
      "Epoch: 1 | Batch: 20/1875 | Loss: 0.8315\n",
      "Epoch: 1 | Batch: 30/1875 | Loss: 0.4282\n",
      "Epoch: 1 | Batch: 40/1875 | Loss: 0.2008\n",
      "Epoch: 1 | Batch: 50/1875 | Loss: 0.5908\n",
      "Epoch: 1 | Batch: 60/1875 | Loss: 0.7364\n",
      "Epoch: 1 | Batch: 70/1875 | Loss: 0.2092\n",
      "Epoch: 1 | Batch: 80/1875 | Loss: 0.3546\n",
      "Epoch: 1 | Batch: 90/1875 | Loss: 0.3742\n",
      "Epoch: 1 | Batch: 100/1875 | Loss: 0.2603\n",
      "Epoch: 1 | Batch: 110/1875 | Loss: 0.2863\n",
      "Epoch: 1 | Batch: 120/1875 | Loss: 0.1915\n",
      "Epoch: 1 | Batch: 130/1875 | Loss: 0.3074\n",
      "Epoch: 1 | Batch: 140/1875 | Loss: 0.3266\n",
      "Epoch: 1 | Batch: 150/1875 | Loss: 0.0371\n",
      "Epoch: 1 | Batch: 160/1875 | Loss: 0.2933\n",
      "Epoch: 1 | Batch: 170/1875 | Loss: 0.1254\n",
      "Epoch: 1 | Batch: 180/1875 | Loss: 0.2497\n",
      "Epoch: 1 | Batch: 190/1875 | Loss: 0.4148\n",
      "Epoch: 1 | Batch: 200/1875 | Loss: 0.1210\n",
      "Epoch: 1 | Batch: 210/1875 | Loss: 0.1602\n",
      "Epoch: 1 | Batch: 220/1875 | Loss: 0.2440\n",
      "Epoch: 1 | Batch: 230/1875 | Loss: 0.1041\n",
      "Epoch: 1 | Batch: 240/1875 | Loss: 0.2971\n",
      "Epoch: 1 | Batch: 250/1875 | Loss: 0.4063\n",
      "Epoch: 1 | Batch: 260/1875 | Loss: 0.1310\n",
      "Epoch: 1 | Batch: 270/1875 | Loss: 0.2325\n",
      "Epoch: 1 | Batch: 280/1875 | Loss: 0.2418\n",
      "Epoch: 1 | Batch: 290/1875 | Loss: 0.2270\n",
      "Epoch: 1 | Batch: 300/1875 | Loss: 0.1508\n",
      "Epoch: 1 | Batch: 310/1875 | Loss: 0.1215\n",
      "Epoch: 1 | Batch: 320/1875 | Loss: 0.1518\n",
      "Epoch: 1 | Batch: 330/1875 | Loss: 0.0998\n",
      "Epoch: 1 | Batch: 340/1875 | Loss: 0.3211\n",
      "Epoch: 1 | Batch: 350/1875 | Loss: 0.5748\n",
      "Epoch: 1 | Batch: 360/1875 | Loss: 0.4766\n",
      "Epoch: 1 | Batch: 370/1875 | Loss: 0.0329\n",
      "Epoch: 1 | Batch: 380/1875 | Loss: 0.0615\n",
      "Epoch: 1 | Batch: 390/1875 | Loss: 0.4194\n",
      "Epoch: 1 | Batch: 400/1875 | Loss: 0.0706\n",
      "Epoch: 1 | Batch: 410/1875 | Loss: 0.5484\n",
      "Epoch: 1 | Batch: 420/1875 | Loss: 0.0534\n",
      "Epoch: 1 | Batch: 430/1875 | Loss: 0.1583\n",
      "Epoch: 1 | Batch: 440/1875 | Loss: 0.0815\n",
      "Epoch: 1 | Batch: 450/1875 | Loss: 0.1248\n",
      "Epoch: 1 | Batch: 460/1875 | Loss: 0.1214\n",
      "Epoch: 1 | Batch: 470/1875 | Loss: 0.1778\n",
      "Epoch: 1 | Batch: 480/1875 | Loss: 0.0753\n",
      "Epoch: 1 | Batch: 490/1875 | Loss: 0.1635\n",
      "Epoch: 1 | Batch: 500/1875 | Loss: 0.1326\n",
      "Epoch: 1 | Batch: 510/1875 | Loss: 0.1894\n",
      "Epoch: 1 | Batch: 520/1875 | Loss: 0.0406\n",
      "Epoch: 1 | Batch: 530/1875 | Loss: 0.2603\n",
      "Epoch: 1 | Batch: 540/1875 | Loss: 0.0639\n",
      "Epoch: 1 | Batch: 550/1875 | Loss: 0.0736\n",
      "Epoch: 1 | Batch: 560/1875 | Loss: 0.0589\n",
      "Epoch: 1 | Batch: 570/1875 | Loss: 0.1212\n",
      "Epoch: 1 | Batch: 580/1875 | Loss: 0.0584\n",
      "Epoch: 1 | Batch: 590/1875 | Loss: 0.0499\n",
      "Epoch: 1 | Batch: 600/1875 | Loss: 0.0611\n",
      "Epoch: 1 | Batch: 610/1875 | Loss: 0.0726\n",
      "Epoch: 1 | Batch: 620/1875 | Loss: 0.0867\n",
      "Epoch: 1 | Batch: 630/1875 | Loss: 0.1177\n",
      "Epoch: 1 | Batch: 640/1875 | Loss: 0.3084\n",
      "Epoch: 1 | Batch: 650/1875 | Loss: 0.0432\n",
      "Epoch: 1 | Batch: 660/1875 | Loss: 0.0071\n",
      "Epoch: 1 | Batch: 670/1875 | Loss: 0.0256\n",
      "Epoch: 1 | Batch: 680/1875 | Loss: 0.1559\n",
      "Epoch: 1 | Batch: 690/1875 | Loss: 0.1888\n",
      "Epoch: 1 | Batch: 700/1875 | Loss: 0.0499\n",
      "Epoch: 1 | Batch: 710/1875 | Loss: 0.0328\n",
      "Epoch: 1 | Batch: 720/1875 | Loss: 0.0623\n",
      "Epoch: 1 | Batch: 730/1875 | Loss: 0.2484\n",
      "Epoch: 1 | Batch: 740/1875 | Loss: 0.0119\n",
      "Epoch: 1 | Batch: 750/1875 | Loss: 0.1131\n",
      "Epoch: 1 | Batch: 760/1875 | Loss: 0.1595\n",
      "Epoch: 1 | Batch: 770/1875 | Loss: 0.0606\n",
      "Epoch: 1 | Batch: 780/1875 | Loss: 0.3731\n",
      "Epoch: 1 | Batch: 790/1875 | Loss: 0.0848\n",
      "Epoch: 1 | Batch: 800/1875 | Loss: 0.0391\n",
      "Epoch: 1 | Batch: 810/1875 | Loss: 0.1088\n",
      "Epoch: 1 | Batch: 820/1875 | Loss: 0.1301\n",
      "Epoch: 1 | Batch: 830/1875 | Loss: 0.1973\n",
      "Epoch: 1 | Batch: 840/1875 | Loss: 0.2214\n",
      "Epoch: 1 | Batch: 850/1875 | Loss: 0.0521\n",
      "Epoch: 1 | Batch: 860/1875 | Loss: 0.0181\n",
      "Epoch: 1 | Batch: 870/1875 | Loss: 0.2609\n",
      "Epoch: 1 | Batch: 880/1875 | Loss: 0.0142\n",
      "Epoch: 1 | Batch: 890/1875 | Loss: 0.1823\n",
      "Epoch: 1 | Batch: 900/1875 | Loss: 0.0236\n",
      "Epoch: 1 | Batch: 910/1875 | Loss: 0.0991\n",
      "Epoch: 1 | Batch: 920/1875 | Loss: 0.3433\n",
      "Epoch: 1 | Batch: 930/1875 | Loss: 0.0266\n",
      "Epoch: 1 | Batch: 940/1875 | Loss: 0.0334\n",
      "Epoch: 1 | Batch: 950/1875 | Loss: 0.0232\n",
      "Epoch: 1 | Batch: 960/1875 | Loss: 0.1608\n",
      "Epoch: 1 | Batch: 970/1875 | Loss: 0.3333\n",
      "Epoch: 1 | Batch: 980/1875 | Loss: 0.0284\n",
      "Epoch: 1 | Batch: 990/1875 | Loss: 0.0272\n",
      "Epoch: 1 | Batch: 1000/1875 | Loss: 0.0707\n",
      "Epoch: 1 | Batch: 1010/1875 | Loss: 0.2640\n",
      "Epoch: 1 | Batch: 1020/1875 | Loss: 0.1029\n",
      "Epoch: 1 | Batch: 1030/1875 | Loss: 0.0902\n",
      "Epoch: 1 | Batch: 1040/1875 | Loss: 0.1375\n",
      "Epoch: 1 | Batch: 1050/1875 | Loss: 0.1302\n",
      "Epoch: 1 | Batch: 1060/1875 | Loss: 0.1516\n",
      "Epoch: 1 | Batch: 1070/1875 | Loss: 0.1550\n",
      "Epoch: 1 | Batch: 1080/1875 | Loss: 0.0628\n",
      "Epoch: 1 | Batch: 1090/1875 | Loss: 0.0752\n",
      "Epoch: 1 | Batch: 1100/1875 | Loss: 0.0123\n",
      "Epoch: 1 | Batch: 1110/1875 | Loss: 0.0438\n",
      "Epoch: 1 | Batch: 1120/1875 | Loss: 0.1768\n",
      "Epoch: 1 | Batch: 1130/1875 | Loss: 0.1267\n",
      "Epoch: 1 | Batch: 1140/1875 | Loss: 0.1421\n",
      "Epoch: 1 | Batch: 1150/1875 | Loss: 0.0353\n",
      "Epoch: 1 | Batch: 1160/1875 | Loss: 0.1317\n",
      "Epoch: 1 | Batch: 1170/1875 | Loss: 0.0192\n",
      "Epoch: 1 | Batch: 1180/1875 | Loss: 0.0068\n",
      "Epoch: 1 | Batch: 1190/1875 | Loss: 0.4557\n",
      "Epoch: 1 | Batch: 1200/1875 | Loss: 0.0214\n",
      "Epoch: 1 | Batch: 1210/1875 | Loss: 0.0108\n",
      "Epoch: 1 | Batch: 1220/1875 | Loss: 0.0148\n",
      "Epoch: 1 | Batch: 1230/1875 | Loss: 0.0345\n",
      "Epoch: 1 | Batch: 1240/1875 | Loss: 0.1668\n",
      "Epoch: 1 | Batch: 1250/1875 | Loss: 0.0804\n",
      "Epoch: 1 | Batch: 1260/1875 | Loss: 0.0853\n",
      "Epoch: 1 | Batch: 1270/1875 | Loss: 0.1097\n",
      "Epoch: 1 | Batch: 1280/1875 | Loss: 0.2725\n",
      "Epoch: 1 | Batch: 1290/1875 | Loss: 0.2292\n",
      "Epoch: 1 | Batch: 1300/1875 | Loss: 0.0619\n",
      "Epoch: 1 | Batch: 1310/1875 | Loss: 0.1970\n",
      "Epoch: 1 | Batch: 1320/1875 | Loss: 0.0222\n",
      "Epoch: 1 | Batch: 1330/1875 | Loss: 0.0149\n",
      "Epoch: 1 | Batch: 1340/1875 | Loss: 0.0404\n",
      "Epoch: 1 | Batch: 1350/1875 | Loss: 0.1269\n",
      "Epoch: 1 | Batch: 1360/1875 | Loss: 0.0111\n",
      "Epoch: 1 | Batch: 1370/1875 | Loss: 0.1170\n",
      "Epoch: 1 | Batch: 1380/1875 | Loss: 0.0185\n",
      "Epoch: 1 | Batch: 1390/1875 | Loss: 0.0444\n",
      "Epoch: 1 | Batch: 1400/1875 | Loss: 0.0539\n",
      "Epoch: 1 | Batch: 1410/1875 | Loss: 0.0359\n",
      "Epoch: 1 | Batch: 1420/1875 | Loss: 0.1193\n",
      "Epoch: 1 | Batch: 1430/1875 | Loss: 0.0617\n",
      "Epoch: 1 | Batch: 1440/1875 | Loss: 0.0197\n",
      "Epoch: 1 | Batch: 1450/1875 | Loss: 0.1748\n",
      "Epoch: 1 | Batch: 1460/1875 | Loss: 0.1224\n",
      "Epoch: 1 | Batch: 1470/1875 | Loss: 0.0059\n",
      "Epoch: 1 | Batch: 1480/1875 | Loss: 0.1446\n",
      "Epoch: 1 | Batch: 1490/1875 | Loss: 0.0331\n",
      "Epoch: 1 | Batch: 1500/1875 | Loss: 0.1636\n",
      "Epoch: 1 | Batch: 1510/1875 | Loss: 0.0466\n",
      "Epoch: 1 | Batch: 1520/1875 | Loss: 0.0556\n",
      "Epoch: 1 | Batch: 1530/1875 | Loss: 0.0094\n",
      "Epoch: 1 | Batch: 1540/1875 | Loss: 0.0075\n",
      "Epoch: 1 | Batch: 1550/1875 | Loss: 0.1116\n",
      "Epoch: 1 | Batch: 1560/1875 | Loss: 0.0109\n",
      "Epoch: 1 | Batch: 1570/1875 | Loss: 0.0213\n",
      "Epoch: 1 | Batch: 1580/1875 | Loss: 0.0870\n",
      "Epoch: 1 | Batch: 1590/1875 | Loss: 0.0102\n",
      "Epoch: 1 | Batch: 1600/1875 | Loss: 0.0325\n",
      "Epoch: 1 | Batch: 1610/1875 | Loss: 0.1458\n",
      "Epoch: 1 | Batch: 1620/1875 | Loss: 0.0301\n",
      "Epoch: 1 | Batch: 1630/1875 | Loss: 0.0145\n",
      "Epoch: 1 | Batch: 1640/1875 | Loss: 0.0207\n",
      "Epoch: 1 | Batch: 1650/1875 | Loss: 0.0313\n",
      "Epoch: 1 | Batch: 1660/1875 | Loss: 0.0461\n",
      "Epoch: 1 | Batch: 1670/1875 | Loss: 0.1187\n",
      "Epoch: 1 | Batch: 1680/1875 | Loss: 0.0124\n",
      "Epoch: 1 | Batch: 1690/1875 | Loss: 0.0130\n",
      "Epoch: 1 | Batch: 1700/1875 | Loss: 0.4278\n",
      "Epoch: 1 | Batch: 1710/1875 | Loss: 0.1005\n",
      "Epoch: 1 | Batch: 1720/1875 | Loss: 0.0084\n",
      "Epoch: 1 | Batch: 1730/1875 | Loss: 0.1068\n",
      "Epoch: 1 | Batch: 1740/1875 | Loss: 0.0040\n",
      "Epoch: 1 | Batch: 1750/1875 | Loss: 0.0110\n",
      "Epoch: 1 | Batch: 1760/1875 | Loss: 0.3148\n",
      "Epoch: 1 | Batch: 1770/1875 | Loss: 0.0370\n",
      "Epoch: 1 | Batch: 1780/1875 | Loss: 0.0048\n",
      "Epoch: 1 | Batch: 1790/1875 | Loss: 0.0213\n",
      "Epoch: 1 | Batch: 1800/1875 | Loss: 0.0291\n",
      "Epoch: 1 | Batch: 1810/1875 | Loss: 0.0763\n",
      "Epoch: 1 | Batch: 1820/1875 | Loss: 0.1222\n",
      "Epoch: 1 | Batch: 1830/1875 | Loss: 0.0145\n",
      "Epoch: 1 | Batch: 1840/1875 | Loss: 0.2217\n",
      "Epoch: 1 | Batch: 1850/1875 | Loss: 0.0306\n",
      "Epoch: 1 | Batch: 1860/1875 | Loss: 0.0141\n",
      "Epoch: 1 | Batch: 1870/1875 | Loss: 0.0078\n",
      "\n",
      "训练完成！\n",
      "总耗时: 253.91 秒\n"
     ]
    }
   ],
   "source": [
    "# 训练循环（为了演示，只跑 1 个 Epoch，且只训练 200 个 batch）\n",
    "epochs = 1\n",
    "model.train()\n",
    "\n",
    "print(f\"\\n=== 开始训练 (共 {epochs} 轮) ===\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch + 1} | Batch: {batch_idx}/{len(train_loader)} | \"\n",
    "                f\"Loss: {loss.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    break  # 只训练 1 个 epoch\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n训练完成！\")\n",
    "print(f\"总耗时: {total_time:.2f} 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb436ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 正在进行结构重参数化 (Fuse) ===\n",
      "融合前结构 (打印第一个 Block):\n",
      "RepVGGDW(\n",
      "  (conv): Conv2d_BN(\n",
      "    (c): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
      "    (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), groups=40)\n",
      "  (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 见证奇迹的时刻：结构重参数化 (Fuse)\n",
    "print(\"\\n=== 正在进行结构重参数化 (Fuse) ===\")\n",
    "print(\"融合前结构 (打印第一个 Block):\")\n",
    "print(model.features[1].token_mixer[0])  # 打印一个未融合的 RepVGGDW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5692a9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "融合后结构 (注意看变成了单纯的 Conv2d):\n",
      "RepVGGDW(\n",
      "  (conv): Conv2d_BN(\n",
      "    (c): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
      "    (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv1): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1), groups=40)\n",
      "  (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 执行融合：把多分支结构全部合并成单路卷积\n",
    "# 这一步必须在 eval 模式下做，或者做完之后就不再训练了\n",
    "model.eval()\n",
    "for m in model.modules():\n",
    "    if hasattr(m, \"fuse\"):\n",
    "        m.fuse()\n",
    "\n",
    "print(\"\\n融合后结构 (注意看变成了单纯的 Conv2d):\")\n",
    "print(model.features[1].token_mixer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4829f3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 开始在测试集上评估 (使用融合后的模型) ===\n",
      "测试集准确率: 97.53%\n",
      "评估耗时: 0.89 秒\n"
     ]
    }
   ],
   "source": [
    "# 推理评估：在测试集上评估融合后的模型\n",
    "print(\"\\n=== 开始在测试集上评估 (使用融合后的模型) ===\")\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "eval_start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        # 为了省时间，测试 20 个 batch 就停（约 640 张图）\n",
    "        if total > 600:\n",
    "            break\n",
    "\n",
    "eval_time = time.time() - eval_start\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"测试集准确率: {accuracy:.2f}%\")\n",
    "print(f\"评估耗时: {eval_time:.2f} 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9186c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
