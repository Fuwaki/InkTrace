# è®­ç»ƒç³»ç»Ÿé‡æ„æŒ‡å—

## ğŸ¯ é—®é¢˜æ€»ç»“

åŸæ¥çš„ `train_structural.py` å’Œ `train_dense.py` å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **Checkpoint ç®¡ç†æ··ä¹±**
   - æ ¼å¼ä¸ä¸€è‡´ï¼ˆä¸€ä¸ªæœ‰ schedulerï¼Œä¸€ä¸ªæ²¡æœ‰ï¼‰
   - ç¼ºå°‘å®šæœŸä¿å­˜
   - æ²¡æœ‰è‡ªåŠ¨æ¸…ç†
   - train_dense.py ç”šè‡³æ²¡ä¿å­˜ config

2. **é…ç½®ç®¡ç†åˆ†æ•£**
   - è¶…å‚æ•°åœ¨ï¼šå‘½ä»¤è¡Œå‚æ•°ã€checkpoint å†…ã€ç¡¬ç¼–ç 
   - æ²¡æœ‰é…ç½®æ–‡ä»¶
   - è·¨è„šæœ¬éœ€è¦æ‰‹åŠ¨ä¿æŒå‚æ•°ä¸€è‡´

3. **åˆ†é˜¶æ®µè®­ç»ƒå‰²è£‚**
   - éœ€è¦æ‰‹åŠ¨è¿è¡Œä¸¤ä¸ªè„šæœ¬
   - `--init_from` å’Œ `--resume` å®¹æ˜“æ··æ·†
   - æ¨¡å‹æ¶æ„åˆ‡æ¢ç¼ºå°‘éªŒè¯

4. **å¤§é‡ä»£ç é‡å¤**
   - è®­ç»ƒå¾ªç¯é€»è¾‘å‡ ä¹å®Œå…¨ä¸€æ ·
   - å‚æ•°å®šä¹‰ã€è®¾å¤‡é€‰æ‹©ã€dataloader éƒ½æ˜¯å¤åˆ¶ç²˜è´´

---

## âœ… æ–°ç³»ç»Ÿç‰¹æ€§

### 1. ç»Ÿä¸€é…ç½®æ–‡ä»¶ (YAML)

```yaml
# configs/default.yaml
model:
  embed_dim: 128
  num_layers: 4

training:
  lr: 1e-3
  batch_size: 32
  epochs: 50
  save_interval: 5
  keep_last_n: 3

data:
  img_size: 64
  num_workers: 4

# å¤šé˜¶æ®µé…ç½®
stages:
  - name: "structural"
    epochs: 30
    model:
      full_heads: false
    training:
      mask_ratio: 0.6

  - name: "dense"
    epochs: 50
    init_from: "best_structural.pth"
    model:
      full_heads: true
```

### 2. æ™ºèƒ½ checkpoint ç®¡ç†

```python
# è‡ªåŠ¨åŠŸèƒ½ï¼š
âœ“ å®šæœŸä¿å­˜ï¼ˆæ¯ N epochï¼‰
âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹
âœ“ è‡ªåŠ¨æ¸…ç†æ—§ checkpointï¼ˆä¿ç•™æœ€è¿‘ N ä¸ªï¼‰
âœ“ å®Œæ•´ä¿å­˜ï¼šmodel + optimizer + scheduler + config
âœ“ ä¸€é”®æ¢å¤è®­ç»ƒ
```

checkpoint ç»“æ„ï¼š
```python
{
    "version": 1,
    "epoch": 10,
    "model_state_dict": ...,
    "optimizer_state_dict": ...,
    "scheduler_state_dict": ...,
    "metric": 0.123,
    "config": {...},  # å®Œæ•´é…ç½®
    "metadata": {"stage": "structural"},
    "timestamp": "2024-01-01T12:00:00",
}
```

### 3. ç»Ÿä¸€è®­ç»ƒè„šæœ¬

```bash
# å•é˜¶æ®µè®­ç»ƒ
python train.py --config configs/default.yaml --stage structural

# å¤šé˜¶æ®µè‡ªåŠ¨è®­ç»ƒ
python train.py --config configs/default.yaml --run-all-stages

# æ¢å¤è®­ç»ƒï¼ˆè‡ªåŠ¨æ£€æµ‹é…ç½®ï¼‰
python train.py --resume checkpoints/structural/checkpoint_latest.pth

# ä» checkpoint åˆå§‹åŒ–æ–°è®­ç»ƒ
python train.py --config configs/default.yaml --stage dense \
    --init_from checkpoints/structural/checkpoint_best.pth
```

---

## ğŸ“– è¿ç§»æŒ‡å—

### æ—§çš„è®­ç»ƒæ–¹å¼ï¼ˆç¹çï¼‰

```bash
# 1. Structural pretrain
python train_structural.py --from-scratch \
    --embed-dim 128 --num-layers 4 --lr 1e-3 --epochs 30

# 2. Dense trainingï¼ˆæ‰‹åŠ¨æŒ‡å®šæ‰€æœ‰å‚æ•°ï¼‰
python train_dense.py \
    --init_from checkpoints/best_structural.pth \
    --embed_dim 128 --num_layers 4 \
    --lr 5e-4 --epochs 50 --stage 2
```

**é—®é¢˜**ï¼š
- âŒ éœ€è¦æ‰‹åŠ¨è¿è¡Œä¸¤ä¸ªè„šæœ¬
- âŒ å‚æ•°å¿…é¡»æ‰‹åŠ¨ä¿æŒä¸€è‡´
- âŒ checkpoint æ ¼å¼ä¸ä¸€è‡´
- âŒ æ¢å¤è®­ç»ƒéœ€è¦è®°ä½æ‰€æœ‰å‚æ•°

### æ–°çš„è®­ç»ƒæ–¹å¼ï¼ˆç®€å•ï¼‰

```bash
# æ–¹å¼ 1ï¼šé…ç½®æ–‡ä»¶ + å•é˜¶æ®µ
python train.py --config configs/default.yaml --stage structural

# æ–¹å¼ 2ï¼šä¸€é”®è¿è¡Œæ‰€æœ‰é˜¶æ®µ
python train.py --config configs/default.yaml --run-all-stages

# æ–¹å¼ 3ï¼šæ¢å¤è®­ç»ƒï¼ˆä¸éœ€è¦è®°ä½å‚æ•°ï¼ï¼‰
python train.py --resume checkpoints/structural/checkpoint_latest.pth
```

**ä¼˜åŠ¿**ï¼š
- âœ… ä¸€æ¡å‘½ä»¤å®Œæˆå¤šé˜¶æ®µè®­ç»ƒ
- âœ… é…ç½®ç»Ÿä¸€ç®¡ç†ï¼Œä¸ä¼šå‡ºé”™
- âœ… checkpoint è‡ªåŠ¨ç®¡ç†
- âœ… æ¢å¤è®­ç»ƒé›¶å‚æ•°

---

## ğŸ› ï¸ ä»£ç å¯¹æ¯”

### æ—§ä»£ç ï¼štrain_dense.py (362 è¡Œ)

```python
# 1. å‚æ•°å®šä¹‰ï¼ˆ40+ è¡Œï¼‰
parser = argparse.ArgumentParser()
parser.add_argument("--lr", type=float, default=1e-3)
parser.add_argument("--batch_size", type=int, default=32)
# ... 15+ ä¸ªå‚æ•°

# 2. Checkpoint é€»è¾‘ï¼ˆ50+ è¡Œï¼‰
if args.resume:
    # å®Œå…¨æ¢å¤
    checkpoint = torch.load(args.resume)
    config = checkpoint.get("config", {})
    embed_dim = config.get("embed_dim", args.embed_dim)
    # ... å¤æ‚çš„åŠ è½½é€»è¾‘
elif args.init_from:
    # è·¨ stage ç»§ç»­
    # ... å¦ä¸€å¥—é€»è¾‘

# 3. è®­ç»ƒå¾ªç¯ï¼ˆ100+ è¡Œï¼‰
for epoch in range(start_epoch, args.epochs):
    model.train()
    for imgs, targets in pbar:
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    # Checkpoint ä¿å­˜
    if avg_losses["total"] < best_loss:
        torch.save({...}, "best_dense_model.pth")
```

### æ–°ä»£ç ï¼štrain.py (~300 è¡Œï¼ŒåŒ…å«ä¸¤ä¸ª trainer)

```python
# 1. é…ç½®åŠ è½½ï¼ˆ1 è¡Œï¼‰
config = Config.from_yaml(args.config)

# 2. Trainer åˆ›å»ºï¼ˆå‡ è¡Œï¼‰
trainer = DenseTrainer(config, init_from=args.init_from)

# 3. è®­ç»ƒï¼ˆ1 è¡Œï¼‰
trainer.train(dataloader)

# Checkpoint ç®¡ç†ï¼Ÿè‡ªåŠ¨ï¼
# - å®šæœŸä¿å­˜
# - æœ€ä½³ä¿å­˜
# - è‡ªåŠ¨æ¸…ç†
```

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

### 1. é…ç½®ç®¡ç†

**âœ… DOï¼š** ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶
```yaml
model:
  embed_dim: 128
  lr: 1e-3
```

**âŒ DON'Tï¼š** æ‰€æœ‰å‚æ•°éƒ½ç”¨å‘½ä»¤è¡Œ
```bash
python train.py --embed_dim 128 --lr 1e-3 --batch_size 32 ...
```

### 2. Checkpoint ç®¡ç†

**âœ… DOï¼š** ç»Ÿä¸€æ ¼å¼ï¼Œå®Œæ•´ä¿å­˜
```python
checkpoint = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "scheduler": scheduler.state_dict(),
    "config": full_config,
}
```

**âŒ DON'Tï¼š** åªä¿å­˜æ¨¡å‹
```python
torch.save(model.state_dict(), "model.pth")  # æ— æ³•æ¢å¤è®­ç»ƒï¼
```

### 3. æ¢å¤è®­ç»ƒ

**âœ… DOï¼š** è‡ªåŠ¨æ£€æµ‹é…ç½®
```bash
python train.py --resume checkpoints/latest.pth  # ä» checkpoint è¯»å–é…ç½®
```

**âŒ DON'Tï¼š** æ‰‹åŠ¨æŒ‡å®šå‚æ•°
```bash
python train.py --resume checkpoints/latest.pth \
    --lr 1e-3 --batch_size 32 ...  # å®¹æ˜“å‡ºé”™ï¼
```

### 4. åˆ†é˜¶æ®µè®­ç»ƒ

**âœ… DOï¼š** ç»Ÿä¸€è„šæœ¬ç®¡ç†
```python
for stage in config.stages:
    trainer = create_trainer(stage)
    trainer.train()
```

**âŒ DON'Tï¼š** åˆ†ç¦»çš„è„šæœ¬
```bash
python train_structural.py ...
python train_dense.py ...  # éœ€è¦æ‰‹åŠ¨ç®¡ç†
```

---

## ğŸ”§ å¦‚ä½•è¿ç§»ç°æœ‰ä»£ç 

### æ­¥éª¤ 1ï¼šåˆ›å»ºé…ç½®æ–‡ä»¶

```bash
cp configs/default.yaml configs/my_experiment.yaml
# ç¼–è¾‘é…ç½®
```

### æ­¥éª¤ 2ï¼šä½¿ç”¨æ–°è„šæœ¬

```bash
# æ—§æ–¹å¼
python train_dense.py --lr 1e-3 --epochs 50 --stage 2

# æ–°æ–¹å¼
python train.py --config configs/my_experiment.yaml --stage dense
```

### æ­¥éª¤ 3ï¼šæ—§ checkpoint å…¼å®¹

æ–°ç³»ç»Ÿæ”¯æŒåŠ è½½æ—§ checkpointï¼ˆä¼šå°è¯•å…¼å®¹ï¼‰ï¼š

```python
# åœ¨ train.py ä¸­
if args.resume:
    trainer.load_checkpoint(args.resume)  # è‡ªåŠ¨å¤„ç†æ—§æ ¼å¼
```

---

## ğŸ’¡ è¿›é˜¶åŠŸèƒ½

### 1. é…ç½®ç»§æ‰¿

```yaml
# configs/base.yaml
model:
  embed_dim: 128
  num_layers: 4

training:
  lr: 1e-3
  weight_decay: 1e-4
```

```yaml
# configs/experiment1.yamlï¼ˆç»§æ‰¿ baseï¼‰
extends: base.yaml

training:
  lr: 5e-4  # è¦†ç›–å­¦ä¹ ç‡

data:
  batch_size: 64  # æ–°å¢é…ç½®
```

### 2. è¶…å‚æ•°æœç´¢

```bash
for lr in 1e-3 5e-4 1e-4; do
    python train.py --config configs/default.yaml \
        --stage dense --lr $lr \
        --save_dir sweeps/lr_$lr
done
```

### 3. å®éªŒå¯¹æ¯”

```bash
# TensorBoard å¯¹æ¯”å¤šä¸ªå®éªŒ
tensorboard --logdir runs/

# æˆ–æ¯”è¾ƒ checkpoint
python scripts/compare_checkpoints.py \
    checkpoints/exp1/best.pth \
    checkpoints/exp2/best.pth
```

---

## ğŸ“š æ–‡ä»¶ç»“æ„

```
InkTrace/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml          # é»˜è®¤é…ç½®
â”‚   â”œâ”€â”€ structural.yaml        # Structural pretrain é…ç½®
â”‚   â””â”€â”€ dense.yaml             # Dense training é…ç½®
â”œâ”€â”€ train_lib.py               # è®­ç»ƒæ¡†æ¶ï¼ˆConfig, CheckpointManager, BaseTrainerï¼‰
â”œâ”€â”€ train.py                   # ç»Ÿä¸€è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_structural.py        # æ—§è„šæœ¬ï¼ˆä¿ç•™å…¼å®¹ï¼‰
â”œâ”€â”€ train_dense.py             # æ—§è„šæœ¬ï¼ˆä¿ç•™å…¼å®¹ï¼‰
â””â”€â”€ TRAINING_GUIDE.md          # æœ¬æ–‡æ¡£
```

---

## ğŸ“ æ¨èå·¥ä½œæµ

### æ—¥å¸¸å¼€å‘

```bash
# 1. ç¼–è¾‘é…ç½®
vim configs/my_experiment.yaml

# 2. è®­ç»ƒ
python train.py --config configs/my_experiment.yaml --run-all-stages

# 3. ç›‘æ§
tensorboard --logdir runs/

# 4. å¦‚æœè®­ç»ƒä¸­æ–­
python train.py --resume checkpoints/latest.pth
```

### å®éªŒç®¡ç†

```bash
# ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºé…ç½®
configs/
â”œâ”€â”€ exp_baseline.yaml
â”œâ”€â”€ exp_large_model.yaml
â”œâ”€â”€ exp_high_lr.yaml
â””â”€â”€ exp_long_train.yaml

# è¿è¡Œå¤šä¸ªå®éªŒ
python train.py --config configs/exp_baseline.yaml --run-all-stages &
python train.py --config configs/exp_large_model.yaml --run-all-stages &
```

---

## â“ å¸¸è§é—®é¢˜

**Q: æ—§çš„ train_dense.py è¿˜èƒ½ç”¨å—ï¼Ÿ**
A: å¯ä»¥ï¼Œæ–°ç³»ç»Ÿå…¼å®¹ã€‚ä½†å»ºè®®è¿ç§»åˆ°æ–°ç³»ç»Ÿã€‚

**Q: å¦‚ä½•æ¢å¤æ—§ checkpoint åˆ°æ–°ç³»ç»Ÿï¼Ÿ**
A: ç›´æ¥ä½¿ç”¨ `--resume`ï¼Œä¼šè‡ªåŠ¨å…¼å®¹ï¼š
```bash
python train.py --resume checkpoints/old/best_model.pth
```

**Q: é…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°å†²çªæ—¶ï¼Ÿ**
A: å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼š
```bash
python train.py --config config.yaml --lr 1e-2  # 1e-2 ä¼šè¦†ç›– config ä¸­çš„ lr
```

**Q: å¦‚ä½•åªè¿è¡ŒæŸä¸ªé˜¶æ®µï¼Ÿ**
A: ä½¿ç”¨ `--stage`ï¼š
```bash
python train.py --config config.yaml --stage structural
```

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. **å®‰è£…ä¾èµ–**ï¼šæ–°ç³»ç»Ÿéœ€è¦ PyYAML
   ```bash
   pip install pyyaml
   ```

2. **æµ‹è¯•æ–°ç³»ç»Ÿ**ï¼š
   ```bash
   python train.py --config configs/default.yaml --stage structural --epochs 1
   ```

3. **è¿ç§»é…ç½®**ï¼šå°†ä½ çš„å¸¸ç”¨å‚æ•°å†™å…¥ YAML

4. **äº«å—ç®€åŒ–**ï¼è®­ç»ƒå†ä¹Ÿä¸ä¼šç¹çäº† âœ¨
