# InkTrace V5 è®­ç»ƒæŒ‡å—

## ğŸ¯ è®­ç»ƒç³»ç»Ÿæ¦‚è¿°

InkTrace V5 ä½¿ç”¨ PyTorch Lightning æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„å¤šé˜¶æ®µè®­ç»ƒç³»ç»Ÿï¼Œæ”¯æŒï¼š

- **ç»Ÿä¸€é…ç½®ç®¡ç†**: YAML æ–‡ä»¶å®šä¹‰å…¨å±€é»˜è®¤ + é˜¶æ®µè¦†ç›–
- **å¤šé˜¶æ®µè®­ç»ƒæµæ°´çº¿**: structural â†’ dense â†’ finetune
- **Curriculum Learning**: ä»ç®€å•æ ·æœ¬é€æ¸è¿‡æ¸¡åˆ°å¤æ‚æ ·æœ¬
- **è‡ªåŠ¨ Checkpoint ç®¡ç†**: Top-K + Last ä¿å­˜ç­–ç•¥
- **æ··åˆç²¾åº¦è®­ç»ƒ**: FP16 AMP åŠ é€Ÿ

---

## ğŸ“ é…ç½®æ–‡ä»¶ç»“æ„

é…ç½®æ–‡ä»¶é‡‡ç”¨ **é»˜è®¤å€¼ + è¦†ç›–** çš„è®¾è®¡æ¨¡å¼ï¼š

```yaml
# configs/default.yaml

# å…¨å±€é»˜è®¤é…ç½®ï¼ˆæ‰€æœ‰é˜¶æ®µçš„åŸºç¡€ï¼‰
model:
  embed_dim: 128
  num_layers: 4
  full_heads: true

training:
  lr: 1e-3
  batch_size: 128
  epochs: 50
  # ... æ›´å¤šå‚æ•°

data:
  img_size: 64
  curriculum_stage: 0
  # ...

# è®­ç»ƒæµæ°´çº¿
pipeline:
  order: ["structural", "dense"]
  auto_transfer: true  # è‡ªåŠ¨ä¼ é€’æƒé‡

# é˜¶æ®µå®šä¹‰ï¼ˆè¦†ç›–é»˜è®¤é…ç½®ï¼‰
stages:
  structural:
    model:
      full_heads: false  # è¦†ç›–é»˜è®¤å€¼
    training:
      epochs: 30
      lr: 1e-3
    # ...

  dense:
    init_from: "auto"    # è‡ªåŠ¨ä½¿ç”¨ä¸Šä¸€é˜¶æ®µæœ€ä¼˜
    training:
      epochs: 80
      lr: 5e-4
    curriculum:
      enabled: true
    # ...
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å•é˜¶æ®µè®­ç»ƒ

```bash
# ç»“æ„é¢„è®­ç»ƒ
python train_pl.py --config configs/default.yaml --stage structural

# å¯†é›†é¢„æµ‹è®­ç»ƒ
python train_pl.py --config configs/default.yaml --stage dense

# ä» checkpoint åˆå§‹åŒ–ï¼ˆè¿ç§»å­¦ä¹ ï¼‰
python train_pl.py --config configs/default.yaml --stage dense \
    --init_from checkpoints/structural/last.ckpt

# æ–­ç‚¹ç»­è®­
python train_pl.py --config configs/default.yaml --stage dense \
    --resume checkpoints/dense/last.ckpt
```

### 2. å¤šé˜¶æ®µè‡ªåŠ¨è®­ç»ƒ

```bash
# è¿è¡Œå®Œæ•´æµæ°´çº¿ï¼ˆstructural -> denseï¼‰
python train_pl.py --config configs/default.yaml --run-all-stages

# ä»ä¸­é—´é˜¶æ®µæ¢å¤
python train_pl.py --config configs/default.yaml --run-all-stages \
    --start-from dense
```

### 3. å¿«é€Ÿè°ƒè¯•

```bash
# ä½¿ç”¨ debug é˜¶æ®µé…ç½®ï¼ˆå°æ•°æ®é›†ï¼Œå¿«é€Ÿè¿­ä»£ï¼‰
python train_pl.py --config configs/default.yaml --stage debug
```

### 4. å‘½ä»¤è¡Œè¦†ç›–

```bash
# è¦†ç›–å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ•°
python train_pl.py --config configs/default.yaml --stage dense \
    --lr 1e-4 --epochs 100 --batch_size 64
```

---

## ğŸ“Š è®­ç»ƒé˜¶æ®µè¯´æ˜

### Phase 1: Structural Pretraining (ç»“æ„é¢„è®­ç»ƒ)

**ç›®æ ‡**: è®© Encoder å­¦ä¼šä»æ®‹ç¼ºè¾“å…¥æ¨æ–­å®Œæ•´ç»“æ„

**æ–¹æ³•**:
- Masking + Reconstructionï¼ˆç±»ä¼¼ MAEï¼‰
- å…³é—­è·³è¿ï¼Œå¼ºè¿« Encoder åœ¨ bottleneck ç¼–ç å®Œæ•´ä¿¡æ¯
- åªè¾“å‡º skeleton + tangent

**æ¨èé…ç½®**:
- `epochs: 30`
- `lr: 1e-3`
- `mask_ratio: 0.6`
- `curriculum_stage: 2`ï¼ˆä¸­ç­‰å¤æ‚åº¦ï¼‰

### Phase 2: Dense Prediction (å¯†é›†é¢„æµ‹)

**ç›®æ ‡**: è®­ç»ƒå®Œæ•´çš„ 5-head å¯†é›†é¢„æµ‹

**æ–¹æ³•**:
- å¤šä»»åŠ¡å­¦ä¹  (Skeleton + Keypoints + Tangent + Width + Offset)
- ä» structural checkpoint åˆå§‹åŒ–
- å¯ç”¨ Curriculum Learning

**æ¨èé…ç½®**:
- `epochs: 80`
- `lr: 5e-4`
- `curriculum: 0 -> 6, 10 epochs/stage`
- `loss_weights: skeleton=10, keypoints=5, tangent=2, width=1, offset=1`

### Phase 3: End-to-End Finetuning (å¯é€‰)

**ç›®æ ‡**: å…¨æ¨¡å‹å¾®è°ƒï¼Œé€‚åº”æç«¯æƒ…å†µ

**æ–¹æ³•**:
- è§£å†» Encoder
- ä½å­¦ä¹ ç‡å…¨å±€å¾®è°ƒ
- ä½¿ç”¨å¤æ‚æ•°æ®

**æ¨èé…ç½®**:
- `epochs: 20`
- `lr: 1e-4`
- `curriculum_stage: 6`ï¼ˆå¤æ‚æ•°æ®ï¼‰

---

## ğŸ“ Curriculum Learning

æ¸è¿›å¼è®­ç»ƒä»ç®€å•æ ·æœ¬é€æ¸è¿‡æ¸¡åˆ°å¤æ‚æ ·æœ¬ï¼š

| Stage | æè¿° | æ ·æœ¬å¤æ‚åº¦ |
|-------|------|------------|
| 0 | å•ç¬”ç”» | â˜…â˜†â˜†â˜†â˜† |
| 1-3 | å¤šç‹¬ç«‹ç¬”ç”» | â˜…â˜…â˜†â˜†â˜† |
| 4-6 | å¤šæ®µè¿ç»­ç¬”ç”» | â˜…â˜…â˜…â˜†â˜† |
| 7-9 | æ··åˆæ¨¡å¼ | â˜…â˜…â˜…â˜…â˜… |

é…ç½®ç¤ºä¾‹ï¼š
```yaml
curriculum:
  enabled: true
  start_stage: 0
  end_stage: 6
  epochs_per_stage: 10  # æ¯ 10 epoch å‡çº§ä¸€æ¬¡
```

---

## ğŸ“ˆ ç›‘æ§ä¸å¯è§†åŒ–

### TensorBoard

```bash
tensorboard --logdir runs/
```

è®°å½•çš„æŒ‡æ ‡ï¼š
- `train/loss`: æ€»è®­ç»ƒæŸå¤±
- `train/loss_skel`, `train/loss_keys`, etc.: å„ä»»åŠ¡æŸå¤±
- `val/loss`: éªŒè¯æŸå¤±
- `val/iou`, `val/precision`, `val/recall`, `val/f1`: éª¨æ¶åˆ†å‰²æŒ‡æ ‡
- `val/kp_topo_recall`, `val/kp_geo_recall`: å…³é”®ç‚¹å¬å›ç‡
- `curriculum/stage`: å½“å‰ curriculum é˜¶æ®µ
- `train/grad_norm`: æ¢¯åº¦èŒƒæ•°ï¼ˆæ¯ 100 æ­¥ï¼‰

### å¯è§†åŒ–å›è°ƒ

è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾ï¼šè¾“å…¥å›¾åƒ | GT | é¢„æµ‹

é…ç½®ï¼š
```yaml
visualization:
  enabled: true
  num_samples: 4
  log_interval: 1  # æ¯ä¸ª epoch
```

---

## ğŸ’¾ Checkpoint ç®¡ç†

### ä¿å­˜ç­–ç•¥

```yaml
checkpoint:
  save_dir: "checkpoints/dense"
  keep_top_k: 3        # ä¿ç•™æœ€ä¼˜çš„ 3 ä¸ª
  save_last: true      # å§‹ç»ˆä¿å­˜ last.ckpt
  monitor: "val/loss"  # ç›‘æ§æŒ‡æ ‡
  mode: "min"          # è¶Šå°è¶Šå¥½
```

### æ–‡ä»¶ç»“æ„

```
checkpoints/
â”œâ”€â”€ structural/
â”‚   â”œâ”€â”€ epoch10-train_loss0.1234.ckpt
â”‚   â”œâ”€â”€ epoch20-train_loss0.0987.ckpt
â”‚   â””â”€â”€ last.ckpt
â””â”€â”€ dense/
    â”œâ”€â”€ epoch30-val_loss0.0567.ckpt
    â”œâ”€â”€ epoch40-val_loss0.0456.ckpt
    â””â”€â”€ last.ckpt
```

---

## âš™ï¸ Loss æƒé‡è°ƒä¼˜

å„ä»»åŠ¡ Loss çš„æ¨èæƒé‡ï¼š

| ä»»åŠ¡ | æƒé‡ | è¯´æ˜ |
|------|------|------|
| skeleton | 10.0 | æœ€é‡è¦ï¼Œéª¨æ¶åˆ†å‰² |
| keypoints | 5.0 | å…³é”®ç‚¹æ£€æµ‹ |
| tangent | 2.0 | åˆ‡å‘åœºï¼Œå¯¹æ›²çº¿æ‹Ÿåˆé‡è¦ |
| width | 1.0 | å®½åº¦é¢„æµ‹ |
| offset | 1.0 | äºšåƒç´ åç§» |

---

## ğŸ”§ å¸¸è§é—®é¢˜

# æ¢å¤è®­ç»ƒï¼ˆè‡ªåŠ¨æ£€æµ‹é…ç½®ï¼‰
python train.py --resume checkpoints/structural/checkpoint_latest.pth

# ä» checkpoint åˆå§‹åŒ–æ–°è®­ç»ƒ
python train.py --config configs/default.yaml --stage dense \
    --init_from checkpoints/structural/checkpoint_best.pth
```

---

## ğŸ“– è¿ç§»æŒ‡å—

### æ—§çš„è®­ç»ƒæ–¹å¼ï¼ˆç¹çï¼‰

```bash
# 1. Structural pretrain
python train_structural.py --from-scratch \
    --embed-dim 128 --num-layers 4 --lr 1e-3 --epochs 30

# 2. Dense trainingï¼ˆæ‰‹åŠ¨æŒ‡å®šæ‰€æœ‰å‚æ•°ï¼‰
python train_dense.py \
    --init_from checkpoints/best_structural.pth \
    --embed_dim 128 --num_layers 4 \
    --lr 5e-4 --epochs 50 --stage 2
```

**é—®é¢˜**ï¼š
- âŒ éœ€è¦æ‰‹åŠ¨è¿è¡Œä¸¤ä¸ªè„šæœ¬
- âŒ å‚æ•°å¿…é¡»æ‰‹åŠ¨ä¿æŒä¸€è‡´
- âŒ checkpoint æ ¼å¼ä¸ä¸€è‡´
- âŒ æ¢å¤è®­ç»ƒéœ€è¦è®°ä½æ‰€æœ‰å‚æ•°

### æ–°çš„è®­ç»ƒæ–¹å¼ï¼ˆç®€å•ï¼‰

```bash
# æ–¹å¼ 1ï¼šé…ç½®æ–‡ä»¶ + å•é˜¶æ®µ
python train.py --config configs/default.yaml --stage structural

# æ–¹å¼ 2ï¼šä¸€é”®è¿è¡Œæ‰€æœ‰é˜¶æ®µ
python train.py --config configs/default.yaml --run-all-stages

# æ–¹å¼ 3ï¼šæ¢å¤è®­ç»ƒï¼ˆä¸éœ€è¦è®°ä½å‚æ•°ï¼ï¼‰
python train.py --resume checkpoints/structural/checkpoint_latest.pth
```

**ä¼˜åŠ¿**ï¼š
- âœ… ä¸€æ¡å‘½ä»¤å®Œæˆå¤šé˜¶æ®µè®­ç»ƒ
- âœ… é…ç½®ç»Ÿä¸€ç®¡ç†ï¼Œä¸ä¼šå‡ºé”™
- âœ… checkpoint è‡ªåŠ¨ç®¡ç†
- âœ… æ¢å¤è®­ç»ƒé›¶å‚æ•°

---

## ğŸ› ï¸ ä»£ç å¯¹æ¯”

### æ—§ä»£ç ï¼štrain_dense.py (362 è¡Œ)

```python
# 1. å‚æ•°å®šä¹‰ï¼ˆ40+ è¡Œï¼‰
parser = argparse.ArgumentParser()
parser.add_argument("--lr", type=float, default=1e-3)
parser.add_argument("--batch_size", type=int, default=32)
# ... 15+ ä¸ªå‚æ•°

# 2. Checkpoint é€»è¾‘ï¼ˆ50+ è¡Œï¼‰
if args.resume:
    # å®Œå…¨æ¢å¤
    checkpoint = torch.load(args.resume)
    config = checkpoint.get("config", {})
    embed_dim = config.get("embed_dim", args.embed_dim)
    # ... å¤æ‚çš„åŠ è½½é€»è¾‘
elif args.init_from:
    # è·¨ stage ç»§ç»­
    # ... å¦ä¸€å¥—é€»è¾‘

# 3. è®­ç»ƒå¾ªç¯ï¼ˆ100+ è¡Œï¼‰
for epoch in range(start_epoch, args.epochs):
    model.train()
    for imgs, targets in pbar:
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    # Checkpoint ä¿å­˜
    if avg_losses["total"] < best_loss:
        torch.save({...}, "best_dense_model.pth")
```

### æ–°ä»£ç ï¼štrain.py (~300 è¡Œï¼ŒåŒ…å«ä¸¤ä¸ª trainer)

```python
# 1. é…ç½®åŠ è½½ï¼ˆ1 è¡Œï¼‰
config = Config.from_yaml(args.config)

# 2. Trainer åˆ›å»ºï¼ˆå‡ è¡Œï¼‰
trainer = DenseTrainer(config, init_from=args.init_from)

# 3. è®­ç»ƒï¼ˆ1 è¡Œï¼‰
trainer.train(dataloader)

# Checkpoint ç®¡ç†ï¼Ÿè‡ªåŠ¨ï¼
# - å®šæœŸä¿å­˜
# - æœ€ä½³ä¿å­˜
# - è‡ªåŠ¨æ¸…ç†
```

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

### 1. é…ç½®ç®¡ç†

**âœ… DOï¼š** ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶
```yaml
model:
  embed_dim: 128
  lr: 1e-3
```

**âŒ DON'Tï¼š** æ‰€æœ‰å‚æ•°éƒ½ç”¨å‘½ä»¤è¡Œ
```bash
python train.py --embed_dim 128 --lr 1e-3 --batch_size 32 ...
```

### 2. Checkpoint ç®¡ç†

**âœ… DOï¼š** ç»Ÿä¸€æ ¼å¼ï¼Œå®Œæ•´ä¿å­˜
```python
checkpoint = {
    "model": model.state_dict(),
    "optimizer": optimizer.state_dict(),
    "scheduler": scheduler.state_dict(),
    "config": full_config,
}
```

**âŒ DON'Tï¼š** åªä¿å­˜æ¨¡å‹
```python
torch.save(model.state_dict(), "model.pth")  # æ— æ³•æ¢å¤è®­ç»ƒï¼
```

### 3. æ¢å¤è®­ç»ƒ

**âœ… DOï¼š** è‡ªåŠ¨æ£€æµ‹é…ç½®
```bash
python train.py --resume checkpoints/latest.pth  # ä» checkpoint è¯»å–é…ç½®
```

**âŒ DON'Tï¼š** æ‰‹åŠ¨æŒ‡å®šå‚æ•°
```bash
python train.py --resume checkpoints/latest.pth \
    --lr 1e-3 --batch_size 32 ...  # å®¹æ˜“å‡ºé”™ï¼
```

### 4. åˆ†é˜¶æ®µè®­ç»ƒ

**âœ… DOï¼š** ç»Ÿä¸€è„šæœ¬ç®¡ç†
```python
for stage in config.stages:
    trainer = create_trainer(stage)
    trainer.train()
```

**âŒ DON'Tï¼š** åˆ†ç¦»çš„è„šæœ¬
```bash
python train_structural.py ...
python train_dense.py ...  # éœ€è¦æ‰‹åŠ¨ç®¡ç†
```

---

## ğŸ”§ å¦‚ä½•è¿ç§»ç°æœ‰ä»£ç 

### æ­¥éª¤ 1ï¼šåˆ›å»ºé…ç½®æ–‡ä»¶

```bash
cp configs/default.yaml configs/my_experiment.yaml
# ç¼–è¾‘é…ç½®
```

### æ­¥éª¤ 2ï¼šä½¿ç”¨æ–°è„šæœ¬

```bash
# æ—§æ–¹å¼
python train_dense.py --lr 1e-3 --epochs 50 --stage 2

# æ–°æ–¹å¼
python train.py --config configs/my_experiment.yaml --stage dense
```

### æ­¥éª¤ 3ï¼šæ—§ checkpoint å…¼å®¹

æ–°ç³»ç»Ÿæ”¯æŒåŠ è½½æ—§ checkpointï¼ˆä¼šå°è¯•å…¼å®¹ï¼‰ï¼š

```python
# åœ¨ train.py ä¸­
if args.resume:
    trainer.load_checkpoint(args.resume)  # è‡ªåŠ¨å¤„ç†æ—§æ ¼å¼
```

---

## ğŸ’¡ è¿›é˜¶åŠŸèƒ½

### 1. é…ç½®ç»§æ‰¿

```yaml
# configs/base.yaml
model:
  embed_dim: 128
  num_layers: 4

training:
  lr: 1e-3
  weight_decay: 1e-4
```

```yaml
# configs/experiment1.yamlï¼ˆç»§æ‰¿ baseï¼‰
extends: base.yaml

training:
  lr: 5e-4  # è¦†ç›–å­¦ä¹ ç‡

data:
  batch_size: 64  # æ–°å¢é…ç½®
```

### 2. è¶…å‚æ•°æœç´¢

```bash
for lr in 1e-3 5e-4 1e-4; do
    python train.py --config configs/default.yaml \
        --stage dense --lr $lr \
        --save_dir sweeps/lr_$lr
done
```

### 3. å®éªŒå¯¹æ¯”

```bash
# TensorBoard å¯¹æ¯”å¤šä¸ªå®éªŒ
tensorboard --logdir runs/

# æˆ–æ¯”è¾ƒ checkpoint
python scripts/compare_checkpoints.py \
    checkpoints/exp1/best.pth \
    checkpoints/exp2/best.pth
```

---

## ğŸ“š æ–‡ä»¶ç»“æ„

```
InkTrace/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml          # é»˜è®¤é…ç½®
â”‚   â”œâ”€â”€ structural.yaml        # Structural pretrain é…ç½®
â”‚   â””â”€â”€ dense.yaml             # Dense training é…ç½®
â”œâ”€â”€ train_lib.py               # è®­ç»ƒæ¡†æ¶ï¼ˆConfig, CheckpointManager, BaseTrainerï¼‰
â”œâ”€â”€ train.py                   # ç»Ÿä¸€è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_structural.py        # æ—§è„šæœ¬ï¼ˆä¿ç•™å…¼å®¹ï¼‰
â”œâ”€â”€ train_dense.py             # æ—§è„šæœ¬ï¼ˆä¿ç•™å…¼å®¹ï¼‰
â””â”€â”€ TRAINING_GUIDE.md          # æœ¬æ–‡æ¡£
```

---

## ğŸ“ æ¨èå·¥ä½œæµ

### æ—¥å¸¸å¼€å‘

```bash
# 1. ç¼–è¾‘é…ç½®
vim configs/my_experiment.yaml

# 2. è®­ç»ƒ
python train.py --config configs/my_experiment.yaml --run-all-stages

# 3. ç›‘æ§
tensorboard --logdir runs/

# 4. å¦‚æœè®­ç»ƒä¸­æ–­
python train.py --resume checkpoints/latest.pth
```

### å®éªŒç®¡ç†

```bash
# ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºé…ç½®
configs/
â”œâ”€â”€ exp_baseline.yaml
â”œâ”€â”€ exp_large_model.yaml
â”œâ”€â”€ exp_high_lr.yaml
â””â”€â”€ exp_long_train.yaml

# è¿è¡Œå¤šä¸ªå®éªŒ
python train.py --config configs/exp_baseline.yaml --run-all-stages &
python train.py --config configs/exp_large_model.yaml --run-all-stages &
```

---

## â“ å¸¸è§é—®é¢˜

**Q: æ—§çš„ train_dense.py è¿˜èƒ½ç”¨å—ï¼Ÿ**
A: å¯ä»¥ï¼Œæ–°ç³»ç»Ÿå…¼å®¹ã€‚ä½†å»ºè®®è¿ç§»åˆ°æ–°ç³»ç»Ÿã€‚

**Q: å¦‚ä½•æ¢å¤æ—§ checkpoint åˆ°æ–°ç³»ç»Ÿï¼Ÿ**
A: ç›´æ¥ä½¿ç”¨ `--resume`ï¼Œä¼šè‡ªåŠ¨å…¼å®¹ï¼š
```bash
python train.py --resume checkpoints/old/best_model.pth
```

**Q: é…ç½®æ–‡ä»¶å’Œå‘½ä»¤è¡Œå‚æ•°å†²çªæ—¶ï¼Ÿ**
A: å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆï¼š
```bash
python train.py --config config.yaml --lr 1e-2  # 1e-2 ä¼šè¦†ç›– config ä¸­çš„ lr
```

**Q: å¦‚ä½•åªè¿è¡ŒæŸä¸ªé˜¶æ®µï¼Ÿ**
A: ä½¿ç”¨ `--stage`ï¼š
```bash
python train.py --config config.yaml --stage structural
```

---

## ğŸš€ ä¸‹ä¸€æ­¥

1. **å®‰è£…ä¾èµ–**ï¼šæ–°ç³»ç»Ÿéœ€è¦ PyYAML
   ```bash
   pip install pyyaml
   ```

2. **æµ‹è¯•æ–°ç³»ç»Ÿ**ï¼š
   ```bash
   python train.py --config configs/default.yaml --stage structural --epochs 1
   ```

3. **è¿ç§»é…ç½®**ï¼šå°†ä½ çš„å¸¸ç”¨å‚æ•°å†™å…¥ YAML

4. **äº«å—ç®€åŒ–**ï¼è®­ç»ƒå†ä¹Ÿä¸ä¼šç¹çäº† âœ¨
