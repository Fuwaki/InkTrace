# =============================================================================
# InkTrace V5 训练配置 (完全重构版)
# =============================================================================
# 设计原则：
#   1. 全局默认值 + 阶段覆盖配置
#   2. 所有参数与代码默认值严格一致
#   3. 移除未使用的参数
#   4. 添加缺失的重要配置
#   5. 参数分类清晰（model/training/data/logging/device）
#
# 使用方法：
#   python train_pl.py --config configs/default.yaml --stage structural
#   python train_pl.py --config configs/default.yaml --stage dense
#   python train_pl.py --config configs/default.yaml --run-all-stages
# =============================================================================


# =============================================================================
# 全局默认配置 (所有阶段的基础)
# =============================================================================

model:
  # ----------------------------------------------------------------------
  # Encoder 配置 (StrokeEncoder)
  # ----------------------------------------------------------------------
  embed_dim: 192          # Transformer embedding 维度 (更宽的表达)
  num_layers: 4           # Transformer 层数 (更快的训练)
  num_heads: 6            # Attention 头数 (192/6=32, 标准head_dim)
  dropout: 0.1            # Dropout 率

  # ----------------------------------------------------------------------
  # Decoder 配置 (UniversalDecoder)
  # ----------------------------------------------------------------------
  decoder_heads: 64       # Decoder head channels (固定值)
  decoder_kernel: 7       # NeXtBlock kernel size (固定值)

  # ----------------------------------------------------------------------
  # 训练模式
  # ----------------------------------------------------------------------
  full_heads: true        # 是否输出全部 5 个预测头

  # ----------------------------------------------------------------------
  # Structural 预训练配置
  # ----------------------------------------------------------------------
  mask_ratio: 0.6         # 遮挡比例 (0.0-1.0)
  mask_strategy: "block"  # 遮挡策略: "block" | "random"
  mask_block_size: 8      # block 策略时的块大小 (像素)

training:
  # ----------------------------------------------------------------------
  # 基础训练参数
  # ----------------------------------------------------------------------
  lr: 1e-3                # 初始学习率
  batch_size: 128         # 批次大小
  epochs: 50              # 训练轮数
  epoch_length: 10000     # 每个 epoch 的样本数

  # 优化器参数
  weight_decay: 1e-4      # AdamW 权重衰减
  grad_clip: 1.0          # 梯度裁剪阈值 (max norm)

  # ----------------------------------------------------------------------
  # 学习率调度器
  # ----------------------------------------------------------------------
  scheduler:
    type: "onecycle"      # 调度器类型: "onecycle" | "cosine" | "constant"
    warmup_epochs: 2      # 预热轮数
    pct_start: 0.1        # OneCycleLR: warmup 占总步数比例

  # ----------------------------------------------------------------------
  # Checkpoint 管理
  # ----------------------------------------------------------------------
  checkpoint:
    save_dir: "checkpoints"
    keep_top_k: 3         # 保留 top-k 最优 checkpoint
    save_last: true       # 始终保存 last.ckpt
    monitor: "val/loss"   # 监控指标
    mode: "min"           # 优化方向: "min" | "max"

  # ----------------------------------------------------------------------
  # Loss 权重 (Dense 阶段使用)
  # ----------------------------------------------------------------------
  loss_weights:
    skeleton: 10.0        # 骨架 (最重要)
    keypoints: 5.0        # 关键点 (拓扑节点)
    tangent: 2.0          # 切向场 (对拟合重要)
    width: 1.0            # 宽度
    offset: 1.0           # 亚像素偏移

  # ----------------------------------------------------------------------
  # Curriculum Learning (渐进式训练)
  # ----------------------------------------------------------------------
  curriculum:
    enabled: false        # 默认关闭，在具体阶段开启
    start_stage: 0        # 起始阶段 (0-9)
    end_stage: 6          # 结束阶段 (建议 6)
    epochs_per_stage: 10  # 每个阶段训练轮数

  # ----------------------------------------------------------------------
  # 可视化配置
  # ----------------------------------------------------------------------
  visualization:
    enabled: true
    num_samples: 4        # 每次可视化样本数
    log_interval: 1       # 每 N epoch 可视化一次
    log_metrics: true     # 记录 IoU/Precision/Recall

data:
  # ----------------------------------------------------------------------
  # 数据增强
  # ----------------------------------------------------------------------
  img_size: 64            # 图像尺寸 (方形)

  # ----------------------------------------------------------------------
  # DataLoader 配置
  # ----------------------------------------------------------------------
  batch_size: 128         # 批次大小 (与 training.batch_size 保持一致)
  num_workers: 8          # DataLoader worker 数量
  pin_memory: true        # 是否使用 pin_memory (加速 GPU 传输)
  persistent_workers: true # 保持 worker 进程 (减少启动开销)

  # ----------------------------------------------------------------------
  # 数据生成配置
  # ----------------------------------------------------------------------
  rust_threads: null      # Rust 生成器线程数 (null=自动)
  curriculum_stage: 0     # 初始 curriculum 阶段 (0-9)

  # ----------------------------------------------------------------------
  # Ground Truth 生成
  # ----------------------------------------------------------------------
  keypoint_sigma: 1.5     # 高斯热力图标准差 (关键点)

logging:
  log_interval: 10        # 每 N step 记录一次
  tensorboard_dir: "runs" # TensorBoard 日志目录

device:
  accelerator: "auto"     # 加速器: "auto" | "gpu" | "cpu" | "mps"
  precision: "16-mixed"   # 精度: "32" | "16-mixed" | "bf16-mixed"


# =============================================================================
# 多阶段训练流水线 (Pipeline)
# =============================================================================

pipeline:
  # 训练顺序 (按列表顺序执行)
  order:
    - "structural"
    - "dense"

  # 自动权重传递
  auto_transfer: true     # 将上一阶段的最优权重传递给下一阶段


# =============================================================================
# 阶段定义 (覆盖配置)
# =============================================================================
# Curriculum Stages 说明:
#   Stage 0:   单笔画 (最简单)
#   Stage 1-3: 多独立笔画 (递增: 1-3, 2-5, 3-8 笔画)
#   Stage 4-6: 多段连续笔画 (递增: 2-3, 3-5, 4-8 段)
#   Stage 7-9: 混合模式 (多条多段路径, 最复杂)
# =============================================================================

stages:
  # =========================================================================
  # Phase 1: Structural Pretraining (结构预训练)
  # =========================================================================
  # 目标：让 Encoder 学会从残缺输入推断完整结构
  # 方法：Masking + Reconstruction (类似 MAE)
  # 特点：关闭跳连，强迫 Encoder 在 bottleneck 编码完整信息
  # =========================================================================
  structural:
    description: "结构预训练：遮挡重建任务"

    model:
      full_heads: false   # 只输出 skeleton + tangent
      mask_ratio: 0.6     # 60% 遮挡
      mask_strategy: "block"

    training:
      lr: 1e-3
      epochs: 30
      epoch_length: 8000
      batch_size: 128

      scheduler:
        type: "onecycle"
        warmup_epochs: 3
        pct_start: 0.1

      checkpoint:
        save_dir: "checkpoints/structural"
        monitor: "train/loss"  # 预训练无验证集
        keep_top_k: 3

      # Loss 权重 (仅 skeleton + tangent)
      loss_weights:
        skeleton: 1.0
        tangent: 1.0

      curriculum:
        enabled: false    # 预训练不用 curriculum

      visualization:
        enabled: true
        num_samples: 4
        log_interval: 2

    data:
      curriculum_stage: 2  # 中等复杂度预训练
      num_workers: 8

  # =========================================================================
  # Phase 2: Dense Prediction Training (密集预测训练)
  # =========================================================================
  # 目标：训练完整的 5-head 密集预测
  # 方法：多任务学习 (Skeleton + Keypoints + Tangent + Width + Offset)
  # 特点：从 structural checkpoint 初始化，使用 curriculum learning
  # =========================================================================
  dense:
    description: "密集预测训练：多任务学习"

    # 权重初始化
    init_from: "auto"     # "auto" = 使用上一阶段最优; 或指定路径
    freeze_encoder: false # 是否冻结 Encoder (可用于迁移学习)

    model:
      full_heads: true    # 输出全部 5 个头

    training:
      lr: 5e-4            # 比预训练低，更稳定
      epochs: 80
      epoch_length: 10000
      batch_size: 128

      scheduler:
        type: "onecycle"
        warmup_epochs: 3
        pct_start: 0.05   # 更短的 warmup

      checkpoint:
        save_dir: "checkpoints/dense"
        monitor: "val/loss"
        keep_top_k: 5

      # Loss 权重 (精调)
      loss_weights:
        skeleton: 10.0    # 最重要
        keypoints: 5.0    # 关键点
        tangent: 2.0      # 对曲线拟合重要
        width: 1.0
        offset: 1.0

      # Curriculum Learning
      curriculum:
        enabled: true
        start_stage: 0
        end_stage: 6
        epochs_per_stage: 10

      visualization:
        enabled: true
        num_samples: 4
        log_interval: 1
        log_metrics: true

    data:
      curriculum_stage: 0  # 从简单开始
      num_workers: 8

  # =========================================================================
  # Phase 3: End-to-End Finetuning (端到端微调，可选)
  # =========================================================================
  finetune:
    description: "端到端微调（可选）"

    init_from: "auto"
    freeze_encoder: false

    model:
      full_heads: true

    training:
      lr: 1e-4            # 更低学习率
      epochs: 20
      epoch_length: 10000
      batch_size: 128

      scheduler:
        type: "cosine"
        warmup_epochs: 1

      checkpoint:
        save_dir: "checkpoints/finetune"
        monitor: "val/loss"
        keep_top_k: 3

      loss_weights:
        skeleton: 10.0
        keypoints: 5.0
        tangent: 2.0
        width: 1.0
        offset: 1.0

      curriculum:
        enabled: false    # 微调阶段不用 curriculum

      visualization:
        enabled: true
        num_samples: 4

    data:
      curriculum_stage: 6  # 直接使用复杂数据

  # =========================================================================
  # Debug: 快速调试配置
  # =========================================================================
  debug:
    description: "快速调试配置"

    model:
      full_heads: true

    training:
      lr: 1e-3
      epochs: 3
      epoch_length: 320   # 很小，快速迭代
      batch_size: 32

      checkpoint:
        save_dir: "checkpoints/debug"
        keep_top_k: 1

      curriculum:
        enabled: false

      visualization:
        enabled: true
        num_samples: 2
        log_interval: 1

    data:
      num_workers: 2
      curriculum_stage: 0
